{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iypc-team/CoLab/blob/master/data_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJIEjEIBdf-h"
      },
      "source": [
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y0JtWBNR9E5"
      },
      "source": [
        "try: import tensorflow as tf\n",
        "except ModuleNotFoundError:\n",
        "    %pip install tensorflow\n",
        "    import tensorflow as tf\n",
        "\n",
        "try: import matplotlib.pyplot as plt\n",
        "except ModuleNotFoundError:\n",
        "    %pip install matplotlib\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "try: import pandas as pd\n",
        "except ModuleNotFoundError:\n",
        "    %pip install pandas\n",
        "    import pandas as pd\n",
        "\n",
        "try: \n",
        "    import numpy as np\n",
        "    np.set_printoptions(precision=4)\n",
        "except ModuleNotFoundError:\n",
        "    %pip install numpy\n",
        "    import numpy as np\n",
        "    np.set_printoptions(precision=4)\n",
        "\n",
        "import pathlib\n",
        "import os\n",
        "from os.path import *\n",
        "# import matplotlib.pyplot as plt\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "import shutil\n",
        "\n",
        "contentPth = os.getcwd()\n",
        "\n",
        "if contentPth == '/content':\n",
        "    gdrivePth = join(contentPth, 'gdrive')\n",
        "    myDrivePth = join(gdrivePth, 'My Drive')\n",
        "    tfImagesPth = join(myDrivePth, 'TensorflowImages')\n",
        "else: tfImagesPth = join(contentPth, 'TensorflowImages')\n",
        "\n",
        "if os.path.exists('/content/sample_data'):\n",
        "    shutil.rmtree('/content/sample_data')\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.flush_and_unmount()\n",
        "    drive.mount('/content/gdrive', force_remount=True)\n",
        "    os.chdir(myDrivePth)\n",
        "    from BashColors import C\n",
        "    from TarfileFunctions import tff\n",
        "    os.chdir(contentPth)\n",
        "except ModuleNotFoundError:\n",
        "    os.chdir(contentPth)\n",
        "    from BashColors import C\n",
        "    from TarfileFunctions import tff\n",
        "    tfImagesPth = join(contentPth, 'TensorflowImages')\n",
        "\n",
        "print(f'cwd: {C.IBlue}{pathlib.Path.cwd()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-_JCFRQ1CXM"
      },
      "source": [
        "# flowers = tf.keras.utils.get_file(\n",
        "    # 'flower_photos',\n",
        "    # 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "    # untar=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIjPhvQ87jUT"
      },
      "source": [
        "Create the `image.ImageDataGenerator`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPCZeBQE5DfH"
      },
      "source": [
        "img_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my4PxqfH26p6"
      },
      "source": [
        "images, labels = next(img_gen.flow_from_directory(tfImagesPth))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd96nH1w3eKH"
      },
      "source": [
        "print(images.dtype, images.shape)\n",
        "print(labels.dtype, labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvRwvt5E2rTH"
      },
      "source": [
        "ds = tf.data.Dataset.from_generator(\n",
        "    lambda: img_gen.flow_from_directory(tfImagesPth), \n",
        "    output_types=(tf.float32, tf.float32), \n",
        "    output_shapes=([13,256,256,3], [13,3])\n",
        ")\n",
        "\n",
        "ds.element_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcaULBCXj_2_"
      },
      "source": [
        "for images, label in ds.take(10):\n",
        "    print(images.__class__)\n",
        "    print('images.shape: ', images.shape)\n",
        "    print('labels.shape: ', labels.shape)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UkL3ivWtNjR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMGlj8V-u-NH"
      },
      "source": [
        "tf.data.Dataset.list_files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyhZLB8N5jBm"
      },
      "source": [
        "Write a function that manipulates the dataset elements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZObC0debDcr"
      },
      "source": [
        "# Reads an image from a file, decodes it into a dense tensor, and resizes it\n",
        "# to a fixed shape.\n",
        "def parse_image(filename):\n",
        "  parts = tf.strings.split(filename, os.sep)\n",
        "  label = parts[-2]\n",
        "\n",
        "  image = tf.io.read_file(filename)\n",
        "  image = tf.image.decode_jpeg(image)\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  image = tf.image.resize(image, [256, 256])\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0dVJlCA5qHA"
      },
      "source": [
        "Test that it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8xuN_HBzGup"
      },
      "source": [
        "file_path = next(iter(list_ds))\n",
        "image, label = parse_image(file_path)\n",
        "\n",
        "def show(image, label):\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.title(label.numpy().decode('utf-8'))\n",
        "  plt.axis('off')\n",
        "\n",
        "show(image, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3P8N-S55vDu"
      },
      "source": [
        "Map it over the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzO8LI_H5Sk_"
      },
      "source": [
        "images_ds = list_ds.map(parse_image)\n",
        "\n",
        "for image, label in images_ds.take(2):\n",
        "  show(image, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ff7IqB9bDcs"
      },
      "source": [
        "### Applying arbitrary Python logic\n",
        "\n",
        "For performance reasons, use TensorFlow operations for\n",
        "preprocessing your data whenever possible. However, it is sometimes useful to\n",
        "call external Python libraries when parsing your input data. You can use the `tf.py_function()` operation in a `Dataset.map()` transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2u7CeA67DU8"
      },
      "source": [
        "For example, if you want to apply a random rotation, the `tf.image` module only has `tf.image.rot90`, which is not very useful for image augmentation. \n",
        "\n",
        "Note: `tensorflow_addons` has a TensorFlow compatible `rotate` in `tensorflow_addons.image.rotate`.\n",
        "\n",
        "To demonstrate `tf.py_function`, try using the `scipy.ndimage.rotate` function instead:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBUmbERt7Czz"
      },
      "source": [
        "import scipy.ndimage as ndimage\n",
        "\n",
        "def random_rotate_image(image):\n",
        "  image = ndimage.rotate(image, np.random.uniform(-30, 30), reshape=False)\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wEyL7bS9S6t"
      },
      "source": [
        "image, label = next(iter(images_ds))\n",
        "image = random_rotate_image(image)\n",
        "show(image, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxVx7z-ABNyq"
      },
      "source": [
        "To use this function with `Dataset.map` the same caveats apply as with `Dataset.from_generator`, you need to describe the return shapes and types when you apply the function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn2nIu92BMp0"
      },
      "source": [
        "def tf_random_rotate_image(image, label):\n",
        "  im_shape = image.shape\n",
        "  [image,] = tf.py_function(random_rotate_image, [image], [tf.float32])\n",
        "  image.set_shape(im_shape)\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWPqKbTnbDct"
      },
      "source": [
        "rot_ds = images_ds.map(tf_random_rotate_image)\n",
        "\n",
        "for image, label in rot_ds.take(2):\n",
        "  show(image, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykx59-cMBwOT"
      },
      "source": [
        "### Parsing `tf.Example` protocol buffer messages\n",
        "\n",
        "Many input pipelines extract `tf.train.Example` protocol buffer messages from a\n",
        "TFRecord format. Each `tf.train.Example` record contains one or more \"features\",\n",
        "and the input pipeline typically converts these features into tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wnE134b32KY"
      },
      "source": [
        "fsns_test_file = tf.keras.utils.get_file(\"fsns.tfrec\", \"https://storage.googleapis.com/download.tensorflow.org/data/fsns-20160927/testdata/fsns-00000-of-00001\")\n",
        "dataset = tf.data.TFRecordDataset(filenames = [fsns_test_file])\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGypdgYOlXZz"
      },
      "source": [
        "You can work with `tf.train.Example` protos outside of a `tf.data.Dataset` to understand the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4znsVNqnF73C"
      },
      "source": [
        "raw_example = next(iter(dataset))\n",
        "parsed = tf.train.Example.FromString(raw_example.numpy())\n",
        "\n",
        "feature = parsed.features.feature\n",
        "raw_img = feature['image/encoded'].bytes_list.value[0]\n",
        "img = tf.image.decode_png(raw_img)\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "_ = plt.title(feature[\"image/text\"].bytes_list.value[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwzqp8IGC_vQ"
      },
      "source": [
        "raw_example = next(iter(dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2X1dQNfC8Lu"
      },
      "source": [
        "def tf_parse(eg):\n",
        "  example = tf.io.parse_example(\n",
        "      eg[tf.newaxis], {\n",
        "          'image/encoded': tf.io.FixedLenFeature(shape=(), dtype=tf.string),\n",
        "          'image/text': tf.io.FixedLenFeature(shape=(), dtype=tf.string)\n",
        "      })\n",
        "  return example['image/encoded'][0], example['image/text'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGJhKDp_61A_"
      },
      "source": [
        "img, txt = tf_parse(raw_example)\n",
        "print(txt.numpy())\n",
        "print(repr(img.numpy()[:20]), \"...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vFIUFzD5qIC"
      },
      "source": [
        "decoded = dataset.map(tf_parse)\n",
        "decoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRYNYkEej7Ix"
      },
      "source": [
        "image_batch, text_batch = next(iter(decoded.batch(10)))\n",
        "image_batch.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYFKQx3bUBeU"
      },
      "source": [
        "## Iterator Checkpointing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOGg1UFhUE4z"
      },
      "source": [
        "Tensorflow supports [taking checkpoints](https://www.tensorflow.org/guide/checkpoint) so that when your training process restarts it can restore the latest checkpoint to recover most of its progress. In addition to checkpointing the model variables, you can also checkpoint the progress of the dataset iterator. This could be useful if you have a large dataset and don't want to start the dataset from the beginning on each restart. Note however that iterator checkpoints may be large, since transformations such as `shuffle` and `prefetch` require buffering elements within the iterator. \n",
        "\n",
        "To include your iterator in a checkpoint, pass the iterator to the `tf.train.Checkpoint` constructor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fsm9wvKUsNC"
      },
      "source": [
        "range_ds = tf.data.Dataset.range(20)\n",
        "\n",
        "iterator = iter(range_ds)\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(0), iterator=iterator)\n",
        "manager = tf.train.CheckpointManager(ckpt, '/tmp/my_ckpt', max_to_keep=3)\n",
        "\n",
        "print([next(iterator).numpy() for _ in range(5)])\n",
        "\n",
        "save_path = manager.save()\n",
        "\n",
        "print([next(iterator).numpy() for _ in range(5)])\n",
        "\n",
        "ckpt.restore(manager.latest_checkpoint)\n",
        "\n",
        "print([next(iterator).numpy() for _ in range(5)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxWglTwX9Fex"
      },
      "source": [
        "Note: It is not possible to checkpoint an iterator which relies on external state such as a `tf.py_function`. Attempting to do so will raise an exception complaining about the external state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLRdedPpbDdD"
      },
      "source": [
        "## Using tf.data with tf.keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTQe8daMcgFz"
      },
      "source": [
        "The `tf.keras` API simplifies many aspects of creating and executing machine\n",
        "learning models. Its `.fit()` and `.evaluate()` and `.predict()` APIs support datasets as inputs. Here is a quick dataset and model setup:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bfjqm0hOfES"
      },
      "source": [
        "train, test = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "images, labels = train\n",
        "images = images/255.0\n",
        "labels = labels.astype(np.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDhF3rGnbDdD"
      },
      "source": [
        "fmnist_train_ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "fmnist_train_ds = fmnist_train_ds.shuffle(5000).batch(32)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rdogg8CfHs-G"
      },
      "source": [
        " Passing a dataset of `(feature, label)` pairs is all that's needed for `Model.fit` and `Model.evaluate`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cu4kPzOHnlt"
      },
      "source": [
        "model.fit(fmnist_train_ds, epochs=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzpAQfJMJF41"
      },
      "source": [
        "If you pass an infinite dataset, for example by calling `Dataset.repeat()`, you just need to also pass the `steps_per_epoch` argument:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp1BpzlyJinb"
      },
      "source": [
        "model.fit(fmnist_train_ds.repeat(), epochs=2, steps_per_epoch=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTLsw_nqJpTw"
      },
      "source": [
        "For evaluation you can pass the number of evaluation steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnlRHlaL-XUI"
      },
      "source": [
        "loss, accuracy = model.evaluate(fmnist_train_ds)\n",
        "print(\"Loss :\", loss)\n",
        "print(\"Accuracy :\", accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8UBU3CJKEA4"
      },
      "source": [
        "For long datasets, set the number of steps to evaluate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVgamf9HKDon"
      },
      "source": [
        "loss, accuracy = model.evaluate(fmnist_train_ds.repeat(), steps=10)\n",
        "print(\"Loss :\", loss)\n",
        "print(\"Accuracy :\", accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZYhJ_YSIl6w"
      },
      "source": [
        "The labels are not required in when calling `Model.predict`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "343lXJ-pIqWD"
      },
      "source": [
        "predict_ds = tf.data.Dataset.from_tensor_slices(images).batch(32)\n",
        "result = model.predict(predict_ds, steps = 10)\n",
        "print(result.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfzZORwLI202"
      },
      "source": [
        "But the labels are ignored if you do pass a dataset containing them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgQJTPrT-2WF"
      },
      "source": [
        "result = model.predict(fmnist_train_ds, steps = 10)\n",
        "print(result.shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}