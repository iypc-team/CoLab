{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPvL7rJeviZV6y4j4SGoT6y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iypc-team/CoLab/blob/master/Writefile_GetTPU_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "import os, shutil\n",
        "import tensorflow as tf\n",
        "\n",
        "try: shutil.rmtree('/content/sample_data')\n",
        "except: pass\n",
        "print('Updated: 10/18/2022-1')"
      ],
      "metadata": {
        "id": "NLRLEH1PxZdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile GetTPU2.py\n",
        "# Updated: 10/18/2022\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from google.colab import drive\n",
        "import glob, os, re, time, shutil\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "from os.path import abspath, basename, exists, join\n",
        "from pathlib import Path\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.profiler import profiler_client\n",
        "# from tensorflow.python.platform.tf_logging import log\n",
        "import numpy as np\n",
        "np.set_printoptions(4)\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "programStart=time.time()\n",
        "contentPath=os.getcwd()\n",
        "\n",
        "bullshitPath=join(contentPath, 'sample_data')\n",
        "if exists(bullshitPath):\n",
        "    shutil.rmtree(bullshitPath)\n",
        "    print(bullshitPath, 'removed')\n",
        "\n",
        "if not exists('/content/drive'):\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "if not exists('BashColors.py'):\n",
        "    print(contentPath)\n",
        "    print(impPath)\n",
        "    shutil.copy2('/content/drive/MyDrive/BashColors.py', contentPath)\n",
        "    from BashColors import C\n",
        "else:\n",
        "    from BashColors import C\n",
        "    # print(f'{os.path.basename(impPath)}{C.BGreen} exists{C.ColorOff}')\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "class GetTPU(object):\n",
        "    \"\"\"with strategy.scope():\"\"\"\n",
        "    gtp = None\n",
        "    tpu = None\n",
        "    strategy = None\n",
        "\n",
        "    def __init__(self):\n",
        "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        "        self.updated='Updated: 10/18/2022'\n",
        "        self.AUTO = tf.data.experimental.AUTOTUNE\n",
        "        self.gtp = None\n",
        "        self.tpu = None\n",
        "        self.strategy = None\n",
        "\n",
        "        # gtp = GetTPU\n",
        "        self.connectTPU()\n",
        "        tpu = self.getTPU()\n",
        "        strategy = self.getStrategy()\n",
        "\n",
        "        super(object, self).__init__()\n",
        "        \n",
        "    def __iter__(self):\n",
        "        return self\n",
        "    def __len__(self):\n",
        "        return len(self.name)\n",
        "    def __str__(self):\n",
        "        return \"%s(%r)\" % (self.__class__, self.__dict__)\n",
        "        \n",
        "    # def __all__(self) = [GetTPU, tpu, strategy, gtp]\n",
        "\n",
        "    def getTPUInfo(self):\n",
        "        \"\"\" \"\"\"\n",
        "        from tensorflow.python.profiler import profiler_client\n",
        "        tpu_profile_service_address = os.environ['COLAB_TPU_ADDR'].replace('8470', '8466')\n",
        "        print(profiler_client.monitor(tpu_profile_service_address, 100, 2))\n",
        "        tpu_profile_service_address = os.environ['COLAB_TPU_ADDR'].replace('8466', '8470')\n",
        "\n",
        "    def getTPU(self):\n",
        "        \"\"\" \"\"\"\n",
        "        return self.tpu\n",
        "\n",
        "    def getStrategy(self):\n",
        "        \"\"\" \"\"\"\n",
        "        return self.strategy\n",
        "\n",
        "    def connectTPU(self):\n",
        "        \"\"\" \"\"\"\n",
        "        # TPUClusterResolver automatically checks connected TPU on all Google platforms\n",
        "        try:\n",
        "            self.tpu = None\n",
        "            # tpu detection\n",
        "            self.tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "            tf.config.experimental_connect_to_cluster(self.tpu)\n",
        "            tf.tpu.experimental.initialize_tpu_system(self.tpu)\n",
        "            self.strategy = tf.distribute.TPUStrategy(self.tpu)\n",
        "            with self.strategy.scope():\n",
        "                print(f'{C.BIWhite}Number of TPUs: {self.strategy.num_replicas_in_sync}{C.ColorOff}')\n",
        "                # print('using TPU')\n",
        "\n",
        "        except ValueError as err:\n",
        "            print(f'{C.BIRed}{err}{C.ColorOff}')\n",
        "            if tf.config.list_physical_devices('GPU'):\n",
        "                print(tf.config.list_physical_devices(), '\\n')\n",
        "                try:\n",
        "                    self.strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
        "                    print(type(strategy))\n",
        "                    # with strategy.scope():\n",
        "                        # print(f'{C.BIPurple}using GPU{C.ColorOff}')\n",
        "                except:\n",
        "                    self.strategy = tf.distribute.get_strategy()# default strategy for CPU\n",
        "                    # with strategy.scope():\n",
        "                        # print(f'{C.BIRed}using CPU{C.ColorOff}')\n",
        "            \n",
        "            # for clusters of multi-GPU machines\n",
        "            # self.strategy=tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
        "\n",
        "gtp = GetTPU()\n",
        "# gtp.connectTPU()\n",
        "# tpu = gtp.getTPU()\n",
        "strategy = gtp.getStrategy()\n",
        "# print(f'{C.BIWhite}{gtp.updated}{C.ColorOff}')"
      ],
      "metadata": {
        "id": "X5Lz78WLInF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from GetTPU2 import *\n",
        "gtp.getTPUInfo()"
      ],
      "metadata": {
        "id": "dwm2oru3ksff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs=\"\"\"\n",
        "    def getTPUInfo(self):\n",
        "        from tensorflow.python.profiler import profiler_client\n",
        "        tpu_profile_service_address = os.environ['COLAB_TPU_ADDR'].replace('8470', '8466')\n",
        "        print(profiler_client.monitor(tpu_profile_service_address, 100, 2))\n",
        "        tpu_profile_service_address = os.environ['COLAB_TPU_ADDR'].replace('8466', '8470')\n",
        "\n",
        "\n",
        "getTPUInfo()\n",
        "\"\"\"\n",
        "print(bs)"
      ],
      "metadata": {
        "id": "EpbqEMXlH3UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q"
      ],
      "metadata": {
        "id": "0LWNiIOf_F44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "\n",
        "with strategy.scope():\n",
        "    random_image_cpu = tf.random.normal((1000, 1000, 1000, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "bs=\"\"\"\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "tSh73llfKfZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q"
      ],
      "metadata": {
        "id": "b84J0T1llDMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU device not found')\n",
        "else: \n",
        "    print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "XoC2quRXED9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices())\n",
        "if len(tf.config.list_physical_devices()) == 1:\n",
        "    print('using cpu')\n",
        "    \n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    with strategy.scope():\n",
        "        print(strategy)\n",
        "elif len(tf.config.list_physical_devices()) == 2:\n",
        "    print('using gpu')\n",
        "    \n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "    print(strategy)\n",
        "else:\n",
        "    print('tpu')\n"
      ],
      "metadata": {
        "id": "eL5rmDYPlHe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(tf.config.list_physical_devices(), '\\n')\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "elif tf.config.list_physical_devices('TPU'):\n",
        "    print(tf.config.list_physical_devices(), '\\n')\n",
        "    strategy = tf.distribute.TPUStrategy()\n",
        "\n",
        "elif tf.config.list_physical_devices('CPU'):\n",
        "    print(tf.config.list_physical_devices(), '\\n')\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "with strategy.scope():\n",
        "  # Do something interesting\n",
        "    print(tf.Variable(1.))"
      ],
      "metadata": {
        "id": "KwVQXW1Yi9iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(tf.test)"
      ],
      "metadata": {
        "id": "QnBLzqToi96d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTFJblxDeEAc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name() # this will tell you device number (should be 0 with a single GPU)\n",
        "tf.test.gpu_device_name()       # this will tell you device number (should be 0 with a single GPU)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device = tf.config.get_visible_devices()\n",
        "print(len(device))\n",
        "print(device)\n",
        "for dev in device:\n",
        "    print(dev)\n",
        "# dir(tf.config)"
      ],
      "metadata": {
        "id": "vaf0K67UmkZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "try:\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "    print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "    strategy = tf.distribute.TPUStrategy(resolver)\n",
        "except ValueError:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    print(strategy)"
      ],
      "metadata": {
        "id": "oa_qeIaZmFpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(tf.distribute)"
      ],
      "metadata": {
        "id": "O9spiWT1ZhJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.platform.tf_logging import log\n",
        "logicalDevices = tf.config.list_logical_devices()\n",
        "print(type(logicalDevices))\n",
        "print(len(logicalDevices))\n",
        "for dev in logicalDevices:\n",
        "    print(dev)"
      ],
      "metadata": {
        "id": "2Hoi8dh9rEGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs=\"\"\"\n",
        "import tensorflow as tf\n",
        "try:\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "    print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "    strategy = tf.distribute.TPUStrategy(resolver)\n",
        "except ValueError:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\"\"\"\n",
        "print(bs)"
      ],
      "metadata": {
        "id": "F_EoWOCWiEin"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}