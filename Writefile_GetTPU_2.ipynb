{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNoMmA0RfYU3SbtyTW6VePf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iypc-team/CoLab/blob/master/Writefile_GetTPU_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "import os, shutil\n",
        "import tensorflow as tf\n",
        "\n",
        "try: shutil.rmtree('/content/sample_data')\n",
        "except: pass\n",
        "print('Updated: 10/14/2022-7')"
      ],
      "metadata": {
        "id": "NLRLEH1PxZdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile GetTPU2.py\n",
        "# Updated: 10/14/2022\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from google.colab import drive\n",
        "import glob, os, re, time, shutil\n",
        "from os.path import abspath, basename, exists, join\n",
        "from pathlib import Path\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "np.set_printoptions(4)\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "programStart=time.time()\n",
        "contentPath=os.getcwd()\n",
        "\n",
        "bullshitPath=join(contentPath, 'sample_data')\n",
        "if exists(bullshitPath):\n",
        "    shutil.rmtree(bullshitPath)\n",
        "    time.sleep(5)\n",
        "    print(bullshitPath, 'removed')\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/PythonFiles')\n",
        "# print(f'cwd: {Path.cwd()}')\n",
        "# %ls -l\n",
        "\n",
        "os.chdir(contentPath)\n",
        "\n",
        "impPath = '/content/drive/MyDrive/BashColors.py'\n",
        "if not exists('BashColors.py'):\n",
        "    print(contentPath)\n",
        "    print(impPath)\n",
        "    shutil.copy2(impPath, contentPath)\n",
        "    time.sleep(1)\n",
        "    from BashColors import C\n",
        "else:\n",
        "    from BashColors import C\n",
        "    print(f'{os.path.basename(impPath)}{C.BGreen} exists{C.ColorOff}')\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "class GetTPU:\n",
        "    \"\"\"with strategy.scope():\"\"\"\n",
        "    gt = None\n",
        "    tpu = None\n",
        "    strategy = None\n",
        "\n",
        "    def __init__(self):\n",
        "        self.updated='Updated: 10/14/2022'\n",
        "        self.AUTO = tf.data.experimental.AUTOTUNE\n",
        "        self.tpu = None\n",
        "        self.strategy = None\n",
        "        \n",
        "    # def __all__(self) = [GetTPU, tpu, strategy, gt]\n",
        "\n",
        "    def getTPU(self):\n",
        "        return self.tpu\n",
        "\n",
        "    def getStrategy(self):\n",
        "        return self.strategy\n",
        "\n",
        "    def connectTPU(self):\n",
        "        # TPUClusterResolver automatically checks connected TPU on all Google platforms\n",
        "        try:\n",
        "            self.tpu = None\n",
        "            # tpu detection\n",
        "            self.tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "            tf.config.experimental_connect_to_cluster(self.tpu)\n",
        "            tf.tpu.experimental.initialize_tpu_system(self.tpu)\n",
        "            self.strategy = tf.distribute.TPUStrategy(self.tpu)\n",
        "            with self.strategy.scope():\n",
        "                print(f'{C.BGreen}Number of TPUs: {gt.strategy.num_replicas_in_sync}{C.ColorOff}')\n",
        "                # print('using TPU')\n",
        "\n",
        "        except ValueError as err:\n",
        "            # print(err)\n",
        "            if tf.config.list_physical_devices('GPU'):\n",
        "                # print(tf.config.list_physical_devices(), '\\n')\n",
        "                try:\n",
        "                    self.strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
        "                    with strategy.scope():\n",
        "                        print('using GPU')\n",
        "                except:\n",
        "                    self.strategy = tf.distribute.get_strategy()# default strategy for CPU\n",
        "                    with strategy.scope():\n",
        "                        print('using CPU')\n",
        "            \n",
        "            # for clusters of multi-GPU machines\n",
        "            # self.strategy=tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
        "\n",
        "gt = GetTPU()\n",
        "gt.connectTPU()\n",
        "tpu = gt.getTPU()\n",
        "strategy = gt.getStrategy()\n",
        "print(f'{gt.updated}')"
      ],
      "metadata": {
        "id": "X5Lz78WLInF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from GetTPU2 import *"
      ],
      "metadata": {
        "id": "dwm2oru3ksff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q"
      ],
      "metadata": {
        "id": "OEhngfrPc6fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getTPUInfo():\n",
        "    from tensorflow.python.profiler import profiler_client\n",
        "    tpu_profile_service_address = os.environ['COLAB_TPU_ADDR'].replace('8470', '8466')\n",
        "    print(profiler_client.monitor(tpu_profile_service_address, 100, 2))\n",
        "    tpu_profile_service_address = os.environ['COLAB_TPU_ADDR'].replace('8466', '8470')\n",
        "\n",
        "\n",
        "getTPUInfo()"
      ],
      "metadata": {
        "id": "EpbqEMXlH3UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# print(tf.config.list_physical_devices())\n",
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    # print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    tpu_strategy = tf.distribute.TPUStrategy()\n",
        "    with tpu_strategy:\n",
        "        print(tf.config.list_physical_devices)\n",
        "\n",
        "except BaseException as err:\n",
        "    print(err)\n",
        "\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "if tf.config.list_physical_devices('TPU'):\n",
        "    print(tf.config.list_physical_devices())\n",
        "    # tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n"
      ],
      "metadata": {
        "id": "rNjHWW3ic8wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "else:\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "        print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "        tf.config.experimental_connect_to_cluster(tpu)\n",
        "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "        tpu_strategy = tf.distribute.TPUStrategy()\n",
        "    except Exception as err:\n",
        "        print('err:', err)"
      ],
      "metadata": {
        "id": "-Ih2Hf5zQlom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "metadata": {
        "id": "tSh73llfKfZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU device not found')\n",
        "else: \n",
        "    print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "XoC2quRXED9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "if len(tf.config.list_physical_devices()) == 1:\n",
        "    print('using cpu')\n",
        "    \n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    with strategy.scope():\n",
        "        print(strategy)\n",
        "elif len(tf.config.list_physical_devices()) == 2:\n",
        "    print('using gpu')\n",
        "    \n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "    print(strategy)\n",
        "else:\n",
        "    print('tpu')\n"
      ],
      "metadata": {
        "id": "eL5rmDYPlHe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "strategy = None\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(tf.config.list_physical_devices(), '\\n')\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "elif tf.config.list_physical_devices('TPU'):\n",
        "    print(tf.config.list_physical_devices(), '\\n')\n",
        "    strategy = tf.distribute.TPUStrategy()\n",
        "\n",
        "elif tf.config.list_physical_devices('CPU'):\n",
        "    print(tf.config.list_physical_devices(), '\\n')\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "with strategy.scope():\n",
        "  # Do something interesting\n",
        "    print(tf.Variable(1.))"
      ],
      "metadata": {
        "id": "KwVQXW1Yi9iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(tf.test)"
      ],
      "metadata": {
        "id": "QnBLzqToi96d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTFJblxDeEAc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name() # this will tell you device number (should be 0 with a single GPU)\n",
        "tf.test.gpu_device_name()       # this will tell you device number (should be 0 with a single GPU)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device = tf.config.get_visible_devices()\n",
        "print(len(device))\n",
        "print(device)\n",
        "for dev in device:\n",
        "    print(dev)\n",
        "# dir(tf.config)"
      ],
      "metadata": {
        "id": "vaf0K67UmkZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "try:\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "    print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "    strategy = tf.distribute.TPUStrategy(resolver)\n",
        "except ValueError:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    print(strategy)"
      ],
      "metadata": {
        "id": "oa_qeIaZmFpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(tf.distribute)"
      ],
      "metadata": {
        "id": "O9spiWT1ZhJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.platform.tf_logging import log\n",
        "logicalDevices = tf.config.list_logical_devices()\n",
        "print(type(logicalDevices))\n",
        "print(len(logicalDevices))\n",
        "for dev in logicalDevices:\n",
        "    print(dev)"
      ],
      "metadata": {
        "id": "2Hoi8dh9rEGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs=\"\"\"\n",
        "import tensorflow as tf\n",
        "try:\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "    print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "    strategy = tf.distribute.TPUStrategy(resolver)\n",
        "except ValueError:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\"\"\"\n",
        "print(bs)"
      ],
      "metadata": {
        "id": "F_EoWOCWiEin"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}