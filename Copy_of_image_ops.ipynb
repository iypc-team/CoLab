{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of image_ops.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iypc-team/CoLab/blob/master/Copy_of_image_ops.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_QTX_vHGbj7"
      },
      "source": [
        "# !pip install -U tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hVIKCrhWh4a"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "try: import tensorflow_addons as tfa\n",
        "except ModuleNotFoundError:\n",
        "    %pip install -U tensorflow-addons\n",
        "    import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgUsVhBQ6dSg"
      },
      "source": [
        "img_path = tf.keras.utils.get_file('tensorflow.png','https://tensorflow.org/images/tf_logo.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRlvNQdm1YI8"
      },
      "source": [
        "img_raw = tf.io.read_file(img_path)\n",
        "img = tf.io.decode_image(img_raw)\n",
        "img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "img = tf.image.resize(img, [224,224])\n",
        "\n",
        "plt.title(\"Image with shape {}\".format(img.shape))\n",
        "_ = plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clXQrFVa2nN7"
      },
      "source": [
        "### Make a black and white version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbaIkUCS2eNv"
      },
      "source": [
        "bw_img = 1.0 - tf.image.rgb_to_grayscale(img)\n",
        "\n",
        "plt.title(\"Mask image with shape {}\".format(bw_img.shape))\n",
        "_ = plt.imshow(bw_img[...,0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwqfpOm--vV2"
      },
      "source": [
        "# Play with tfa.image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIa5HnomPds3"
      },
      "source": [
        "## Mean filtering\n",
        "Mean filtering is a filtering technique, which is often used to remove noise from an image or signal. The idea is to run through the image pixel by pixel and replacing it with the average values of neighboring pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SutWnbRoHl6i"
      },
      "source": [
        "mean = tfa.image.mean_filter2d(img, filter_shape=11)\n",
        "_ = plt.imshow(mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp6cU7I0-r2h"
      },
      "source": [
        "## Rotate\n",
        "This operation rotates the given image by the angle (in radians) input by the user.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kxUES9sM8Jl"
      },
      "source": [
        "rotate = tfa.image.rotate(img, tf.constant(-np.pi/4))\n",
        "_ = plt.imshow(rotate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjMdSDKlBcPh"
      },
      "source": [
        "## Transform\n",
        "This operation transforms the given image on the basis of the transform vector given by the user. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTh1Qpps8Rg5"
      },
      "source": [
        "transform = tfa.image.transform(img, [1.0, 1.0, -250, 0.0, 1.0, 0.0, 0.0, 0.0])\n",
        "_ = plt.imshow(transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O79BrK-bC8oh"
      },
      "source": [
        "## Random HSV in YIQ\n",
        "This operation changes color scale of a given RGB image to YIQ but here delta hue and saturation values are picked randomly from the given range."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZBI-9XvBSuh"
      },
      "source": [
        "delta = 0.5\n",
        "lower_saturation = 0.1\n",
        "upper_saturation = 0.9\n",
        "lower_value = 0.2\n",
        "upper_value = 0.8\n",
        "rand_hsvinyiq = tfa.image.random_hsv_in_yiq(img, delta, lower_saturation, upper_saturation, lower_value, upper_value)\n",
        "_ = plt.imshow(rand_hsvinyiq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruyvVnmCDBgj"
      },
      "source": [
        "## Adjust HSV in YIQ\n",
        "This operation changes color scale of a given RGB image to YIQ but here instead of choosing randomly, delta hue and saturation values are inputs form the user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbCdwGtYChnQ"
      },
      "source": [
        "delta = 0.5\n",
        "saturation = 0.3\n",
        "value = 0.6\n",
        "adj_hsvinyiq = tfa.image.adjust_hsv_in_yiq(img, delta, saturation, value)\n",
        "_ = plt.imshow(adj_hsvinyiq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdbCDYJkG8Gv"
      },
      "source": [
        "## Dense Image Warp\n",
        "This operation is for non-linear warp of any image specified by the flow field of the offset vector (here used random values for example). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG557eQDDtSK"
      },
      "source": [
        "input_img = tf.image.convert_image_dtype(tf.expand_dims(img, 0), tf.dtypes.float32)\n",
        "\n",
        "flow_shape = [1, input_img.shape[1], input_img.shape[2], 2]\n",
        "init_flows = np.float32(np.random.normal(size=flow_shape) * 2.0)\n",
        "dense_img_warp = tfa.image.dense_image_warp(input_img, init_flows)\n",
        "dense_img_warp = tf.squeeze(dense_img_warp, 0)\n",
        "_ = plt.imshow(dense_img_warp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcLMnSKYPcjA"
      },
      "source": [
        "## Euclidian Distance Transform\n",
        "This operation updates the pixel value with the euclidian distance from the foreground pixel to the background one.\n",
        "* Note : It takes only binary image and results in transformed image. If a different image is given it results in a image with single value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OMh6oeRQaYQ"
      },
      "source": [
        "gray = tf.image.convert_image_dtype(bw_img,tf.uint8)\n",
        "# The op expects a batch of images, so add a batch dimension\n",
        "gray = tf.expand_dims(gray, 0)\n",
        "eucid = tfa.image.euclidean_dist_transform(gray)\n",
        "eucid = tf.squeeze(eucid, (0, -1))\n",
        "_ = plt.imshow(eucid, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}