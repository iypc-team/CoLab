{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CartPole-Krohn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iypc-team/CoLab/blob/master/CartPole_Krohn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek_52FUZJTSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pip install pip\n",
        "print()\n",
        "%pip install tensorflow\n",
        "print()\n",
        "%pip install keras\n",
        "print()\n",
        "%pip install gym\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print('\\n', \"All installs complete\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V63WZCQ6Jtae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from __future__ import  absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals \n",
        "\n",
        "import random\n",
        "import gym\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVmrvqSMrwIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make('CartPole-v1') # Initialize environment\n",
        "state_size = env.observation_space.shape[0]\n",
        "action_size = env.action_space.n\n",
        "batch_size = 32 # default = 32\n",
        "n_episodes = 1001 # default = 1001\n",
        "# n_episodes games we want agent to play\n",
        "output_dir = 'model_output/cartpole'\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"ok\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSM_Oyed2GLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self, state_size, action_size):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=2500) # Default 2000\n",
        "        # deque: double ended queue, acts like a list, Elements can be added or removed from either end\n",
        "        self.gamma = 0.95 # Default 0.95\n",
        "        # decay or discount rate:\n",
        "        # enables agent to take into account future actions \n",
        "        #  in addition to the immediate ones , But discounted at this rate\n",
        "        self. epsilon = 1.0\n",
        "        # How much to hack to randomly, decays over time, According to\n",
        "        self.epsilon_decay = 0.995 # default 0.0995\n",
        "        #  decrease random expressions as agent improves over time \n",
        "        self.epsilon_min = 0.01 # default 0.01\n",
        "        # Minimum amount of random exploration\n",
        "        self.learning_rate = 0.001 # default 0.001\n",
        "        # Rate at which NN adjusts Parameters via SGD To reduce cost\n",
        "        self.model = self._build_model() # Private function\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}