{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/iypc-team/CoLab/blob/master/Copy_of_NewTPU_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9u3d4Z7uQsmp",
    "outputId": "82f2d75d-f4cd-44b1-b487-d69d178cf909"
   },
   "outputs": [],
   "source": [
    "%%writefile GetColabTPU.py\n",
    "# updated: 08/16/2022\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from google.colab import drive\n",
    "import glob, os, re, time, shutil\n",
    "from os.path import abspath, basename, exists, join\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "\n",
    "programStart=time.time()\n",
    "contentPath=os.getcwd()\n",
    "\n",
    "bullshitPath=join(contentPath, 'sample_data')\n",
    "if exists(bullshitPath):\n",
    "    shutil.rmtree(bullshitPath)\n",
    "    time.sleep(5)\n",
    "    print(bullshitPath, 'removed')\n",
    "\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "os.chdir('/content/drive/MyDrive/PythonFiles')\n",
    "print(f'cwd: {Path.cwd()}')\n",
    "# %ls -l\n",
    "rootGlobList=glob.glob('**')\n",
    "for fil in sorted(rootGlobList):\n",
    "    fullPath=abspath(fil)\n",
    "    print(f'{fil}')\n",
    "    print(fullPath)\n",
    "\n",
    "os.chdir(contentPath)\n",
    "\n",
    "impPath = '/content/drive/MyDrive/BashColors.py'\n",
    "if not exists('BashColors.py'):\n",
    "    print(contentPath)\n",
    "    print(impPath)\n",
    "    shutil.copy2(impPath, contentPath)\n",
    "    time.sleep(1)\n",
    "    from BashColors import C\n",
    "else:\n",
    "    from BashColors import C\n",
    "    print(f'{os.path.basename(impPath)}{C.BGreen} exists{C.ColorOff}')\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "class GetTPU:\n",
    "    \"\"\" \"\"\"\n",
    "    gt = None\n",
    "    tpu = None\n",
    "    strategy = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.AUTO = tf.data.experimental.AUTOTUNE\n",
    "        self.tpu = None\n",
    "        self.strategy = None\n",
    "        \n",
    "    def __all__(self) = [GetTPU, tpu, strategy, gt]\n",
    "\n",
    "    def getTPU(self):\n",
    "        return self.tpu\n",
    "\n",
    "    def getStrategy(self):\n",
    "        return self.strategy\n",
    "\n",
    "    def connectTPU(self):\n",
    "        # TPUClusterResolver automatically checks connected TPU on all Google platforms\n",
    "        try:\n",
    "            self.tpu = None\n",
    "            # tpu detection\n",
    "            self.tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
    "            tf.config.experimental_connect_to_cluster(self.tpu)\n",
    "            tf.tpu.experimental.initialize_tpu_system(self.tpu)\n",
    "            self.strategy = tf.distribute.TPUStrategy(self.tpu)\n",
    "\n",
    "        except ValueError as err: \n",
    "            # detect GPUs\n",
    "            print(err)\n",
    "            # for GPU or multi-GPU machines\n",
    "            # self.strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "            # default strategy for CPU and single GPU machines\n",
    "            self.strategy = tf.distribute.get_strategy()\n",
    "            \n",
    "            # for clusters of multi-GPU machines\n",
    "            # self.strategy=tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "\n",
    "gt = GetTPU()\n",
    "gt.connectTPU()\n",
    "print(f'\\nNumber of TPUs: {gt.strategy.num_replicas_in_sync}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N90ebf8bKiqr",
    "outputId": "74fcca56-9a16-4307-ca94-993034c0245c"
   },
   "outputs": [],
   "source": [
    "initStart = time.time()\n",
    "import GetColabTPU\n",
    "from GetColabTPU import *\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "tpu = gt.getTPU()\n",
    "strategy = gt.getStrategy()\n",
    "initEnd = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4EAiF-WNl7Hv",
    "outputId": "597baab3-dc9a-4b41-cdeb-a47c5729ed24"
   },
   "outputs": [],
   "source": [
    "initTime = (initEnd - initStart)\n",
    "initTime= round(initTime, 1)\n",
    "print(f'TPU initialization: {initTime} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lTRg-X0gOKGd",
    "outputId": "ab43424a-8743-40e8-aa09-231e730e7d1e"
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    # Create a simple model.\n",
    "    inputs = tf.keras.Input(shape=(32, ))\n",
    "    outputs = tf.keras.layers.Dense(9)(inputs)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "# Train the model.\n",
    "test_input = np.random.random((128 , 32))\n",
    "test_target = np.random.random((128 , 1))\n",
    "model.fit(test_input, test_target)\n",
    "\n",
    "# Calling `save('my_model')` creates a SavedModel folder `my_model`.\n",
    "# model.save(\"/gdrive/My Drive/SavedModels\")\n",
    "\n",
    "# It can be used to reconstruct the model identically.\n",
    "# reconstructed_model = tf.keras.models.load_model(\"/gdrive/My Drive/SavedModels\")\n",
    "\n",
    "# Let's check:\n",
    "# np.testing.assert_allclose(model.predict(test_input), reconstructed_model.predict(test_input))\n",
    "\n",
    "# The reconstructed model is already compiled and has retained the optimizer\n",
    "# state, so training can resume:\n",
    "# reconstructed_model.fit(test_input, test_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmhaoX78OKG9",
    "outputId": "7c059276-d000-4ad0-c9fc-c1c0d3ab1382"
   },
   "outputs": [],
   "source": [
    "with strategy.scope(): \n",
    "    # creating the model in the TPUStrategy scope places the model on the TPU\n",
    "    model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M3G-2aUBQJ-H"
   },
   "outputs": [],
   "source": [
    "\n",
    "# For image sizes are available for this dataset\n",
    "EPOCHS = 12\n",
    "IMAGE_SIZE = [331, 331]\n",
    "\n",
    "FLOWERS_DATASETS = { # available image sizes\n",
    "    192: 'gs://flowers-public/tfrecords-jpeg-192x192-2/*.tfrec',\n",
    "    224: 'gs://flowers-public/tfrecords-jpeg-224x224/*.tfrec',\n",
    "    331: 'gs://flowers-public/tfrecords-jpeg-331x331/*.tfrec',\n",
    "    512: 'gs://flowers-public/tfrecords-jpeg-512x512/*.tfrec'\n",
    "}\n",
    "CLASSES = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips'] # do not change, maps to the labels in the data (folder names)\n",
    "assert IMAGE_SIZE[0] == IMAGE_SIZE[1], \"only square images are supported\"\n",
    "assert IMAGE_SIZE[0] in FLOWERS_DATASETS, \"this image size is not supported\"\n",
    "\n",
    "\n",
    "# mixed precision\n",
    "# On TPU, bfloat16/float32 mixed precision is automatically used in TPU computations.\n",
    "# Enabling it in Keras also stores relevant variables in bfloat16 format (memory optimization).\n",
    "# On GPU, specifically V100, mixed precision must be enabled for hardware TensorCores to be used.\n",
    "# XLA compilation must be enabled for this to work. (On TPU, XLA compilation is the default)\n",
    "MIXED_PRECISION = False\n",
    "if MIXED_PRECISION:\n",
    "    if tpu: \n",
    "        policy = tf.keras.mixed_precision.experimental.Policy('mixed_bfloat16')\n",
    "    else: #\n",
    "        policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "        tf.config.optimizer.set_jit(True) # XLA compilation\n",
    "    tf.keras.mixed_precision.experimental.set_policy(policy)\n",
    "    print('Mixed precision enabled')\n",
    "\n",
    "# batch and learning rate settings\n",
    "if strategy.num_replicas_in_sync == 8: \n",
    "    # TPU or 8xGPU\n",
    "    BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "    VALIDATION_BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "    start_lr = 0.00001\n",
    "    min_lr = 0.00001\n",
    "    max_lr = 0.00005 * strategy.num_replicas_in_sync\n",
    "    rampup_epochs = 5\n",
    "    sustain_epochs = 0\n",
    "    exp_decay = .8\n",
    "elif strategy.num_replicas_in_sync == 1: \n",
    "    # single GPU\n",
    "    BATCH_SIZE = 16\n",
    "    VALIDATION_BATCH_SIZE = 16\n",
    "    start_lr = 0.00001\n",
    "    min_lr = 0.00001\n",
    "    max_lr = 0.0002\n",
    "    rampup_epochs = 5\n",
    "    sustain_epochs = 0\n",
    "    exp_decay = .8\n",
    "else: # TPU pod\n",
    "    BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
    "    VALIDATION_BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
    "    start_lr = 0.00001\n",
    "    min_lr = 0.00001\n",
    "    max_lr = 0.00002 * strategy.num_replicas_in_sync\n",
    "    rampup_epochs = 7\n",
    "    sustain_epochs = 0\n",
    "    exp_decay = .8\n",
    "\n",
    "def lrfn(epoch):\n",
    "    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n",
    "        if epoch < rampup_epochs:\n",
    "            lr = (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n",
    "        elif epoch < rampup_epochs + sustain_epochs:\n",
    "            lr = max_lr\n",
    "        else:\n",
    "            lr = (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n",
    "        return lr\n",
    "    return lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay)\n",
    "    \n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=True)\n",
    "\n",
    "rng = [i for i in range(EPOCHS)]\n",
    "y = [lrfn(x) for x in rng]\n",
    "# plt.plot(rng, [lrfn(x) for x in rng])\n",
    "# print(y[0], y[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPkvHdAYNt9J"
   },
   "outputs": [],
   "source": [
    "\n",
    "def dataset_to_numpy_util(dataset, N):\n",
    "  dataset = dataset.unbatch().batch(N)\n",
    "  for images, labels in dataset:\n",
    "    numpy_images = images.numpy()\n",
    "    numpy_labels = labels.numpy()\n",
    "    break;  \n",
    "  return numpy_images, numpy_labels\n",
    "\n",
    "def title_from_label_and_target(label, correct_label):\n",
    "  label = np.argmax(label, axis=-1)  # one-hot to class number\n",
    "  correct_label = np.argmax(correct_label, axis=-1) # one-hot to class number\n",
    "  correct = (label == correct_label)\n",
    "  return \"{} [{}{}{}]\".format(CLASSES[label], str(correct), ', shoud be ' if not correct else '',\n",
    "                              CLASSES[correct_label] if not correct else ''), correct\n",
    "\n",
    "def display_one_flower(image, title, subplot, red=False):\n",
    "    plt.subplot(subplot)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "    plt.title(title, fontsize=16, color='red' if red else 'black')\n",
    "    return subplot+1\n",
    "  \n",
    "def display_9_images_from_dataset(dataset):\n",
    "  subplot=331\n",
    "  plt.figure(figsize=(13,13))\n",
    "  images, labels = dataset_to_numpy_util(dataset, 9)\n",
    "  for i, image in enumerate(images):\n",
    "    title = CLASSES[np.argmax(labels[i], axis=-1)]\n",
    "    subplot = display_one_flower(image, title, subplot)\n",
    "    if i >= 8:\n",
    "      break;\n",
    "              \n",
    "  #plt.tight_layout() # bug in tight layout in this version of matplotlib\n",
    "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "  plt.show()\n",
    "  \n",
    "def display_9_images_with_predictions(images, predictions, labels):\n",
    "  subplot=331\n",
    "  plt.figure(figsize=(13,13))\n",
    "  for i, image in enumerate(images):\n",
    "    title, correct = title_from_label_and_target(predictions[i], labels[i])\n",
    "    subplot = display_one_flower(image, title, subplot, not correct)\n",
    "    if i >= 8:\n",
    "      break;\n",
    "              \n",
    "  #plt.tight_layout() # bug in tight layout in this version of matplotlib\n",
    "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "  plt.show()\n",
    "  \n",
    "def display_training_curves(training, validation, title, subplot):\n",
    "  if subplot%10==1: # set up the subplots on the first call\n",
    "    plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
    "    #plt.tight_layout() # bug in tight layout in this version of matplotlib\n",
    "  ax = plt.subplot(subplot)\n",
    "  ax.set_facecolor('#F8F8F8')\n",
    "  ax.plot(training)\n",
    "  ax.plot(validation)\n",
    "  ax.set_title('model '+ title)\n",
    "  ax.set_ylabel(title)\n",
    "  #ax.set_ylim(0.28,1.05)\n",
    "  ax.set_xlabel('epoch')\n",
    "  ax.legend(['train', 'valid.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LtAVr-4CP1rp",
    "outputId": "6f51b6ce-cb8f-41dc-be1c-bd2f5a7fb71d"
   },
   "outputs": [],
   "source": [
    "def count_data_items(filenames):\n",
    "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "gcs_pattern = FLOWERS_DATASETS[IMAGE_SIZE[0]]\n",
    "validation_split = 0.19\n",
    "filenames = tf.io.gfile.glob(gcs_pattern)\n",
    "split = len(filenames) - int(len(filenames) * validation_split)\n",
    "TRAIN_FILENAMES = filenames[:split]\n",
    "VALID_FILENAMES = filenames[split:]\n",
    "TRAIN_STEPS = count_data_items(TRAIN_FILENAMES) // BATCH_SIZE\n",
    "print(\"TRAINING IMAGES: \", count_data_items(TRAIN_FILENAMES), \", STEPS PER EPOCH: \", TRAIN_STEPS)\n",
    "print(\"VALIDATION IMAGES: \", count_data_items(VALID_FILENAMES))\n",
    "        \n",
    "def read_tfrecord(example):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means scalar\n",
    "        \"one_hot_class\": tf.io.VarLenFeature(tf.float32),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "    image = tf.image.decode_jpeg(example['image'], channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    class_label = tf.cast(example['class'], tf.int32)\n",
    "    one_hot_class = tf.sparse.to_dense(example['one_hot_class'])\n",
    "    one_hot_class = tf.reshape(one_hot_class, [5])\n",
    "    return image, one_hot_class\n",
    "    \n",
    "def force_image_sizes(dataset, image_size):\n",
    "    # explicit size will be needed for TPU\n",
    "    reshape_images = lambda image, label: (tf.reshape(image, [*image_size, 3]), label)\n",
    "    dataset = dataset.map(reshape_images, num_parallel_calls=AUTO)\n",
    "    return dataset\n",
    "\n",
    "def load_dataset(filenames):\n",
    "    # read from TFRecords. For optimal performance, use \"interleave(tf.data.TFRecordDataset, ...)\"\n",
    "    # to read from multiple TFRecord files at once and set the option experimental_deterministic = False\n",
    "    # to allow order-altering optimizations.\n",
    "\n",
    "    opt = tf.data.Options()\n",
    "    opt.experimental_deterministic = False\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    dataset = dataset.with_options(opt)\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
    "    dataset = force_image_sizes(dataset, IMAGE_SIZE)\n",
    "    return dataset\n",
    "\n",
    "def data_augment(image, one_hot_class):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_saturation(image, 0, 2)\n",
    "    return image, one_hot_class\n",
    "    \n",
    "# For experts: fine adjustments of tf.data.Dataset distribution behavior:\n",
    "\n",
    "# Replicating a datset with state (even random number generator state) does not replicate the\n",
    "# state and changes the behavior of the dataset. If the state is just the RNG state, it usually\n",
    "# does not matter but this behavior can be adjusted with tf.data.experimental.ExternalStatePolicy:\n",
    "#  WARN = 0   (this is the default in Tensorflow outside of Keras)\n",
    "#  IGNORE = 1 (this is the default in Keras)\n",
    "#  FAIL = 2\n",
    "\n",
    "# On TPU pods, the dataset API attempts to shard the dataset across individual TPUs at the file\n",
    "# level so that TPUs only load the data they will actually train on. This requires more data files \n",
    "# than TPUs in the pod. (ex: TPU v3-32 pod = 4 TPUs => dataset must have at least 4 files)\n",
    "# An error will occur if there are not enough data files. File-level sharding can be disabled:\n",
    "#  opt = tf.data.Options()\n",
    "#  opt.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "#  dataset = dataset.with_options(opt)\n",
    "   \n",
    "\n",
    "def get_training_dataset():\n",
    "    dataset = load_dataset(TRAIN_FILENAMES)\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset():\n",
    "    dataset = load_dataset(VALID_FILENAMES)\n",
    "    dataset = dataset.batch(VALIDATION_BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    \n",
    "    # needed for TPU 32-core pod: the test dataset has only 3 files but there are 4 TPUs. FILE sharding policy must be disabled.\n",
    "    opt = tf.data.Options()\n",
    "    opt.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "    dataset = dataset.with_options(opt)\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22rVDTx8wCqE"
   },
   "source": [
    "## training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wxKyCklR4Gh"
   },
   "outputs": [],
   "source": [
    "\n",
    "training_dataset = get_training_dataset()\n",
    "validation_dataset = get_validation_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xb-b4PRz-V6O",
    "outputId": "ea203fee-10f5-4d4e-8fa7-01739eab4fca"
   },
   "outputs": [],
   "source": [
    "print('validation_dataset')\n",
    "# display_9_images_from_dataset(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALtRUlxhw8Vt"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJl3vNtJOB-x"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # pretrained_model = tf.keras.applications.MobileNetV2(input_shape=[*IMAGE_SIZE, 3], include_top=False)\n",
    "    # pretrained_model = tf.keras.applications.Xception(input_shape=[*IMAGE_SIZE, 3], include_top=False)\n",
    "    #pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "    #pretrained_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=[*IMAGE_SIZE, 3])\n",
    "    pretrained_model = tf.keras.applications.MobileNet(weights='imagenet', include_top=False, input_shape=[*IMAGE_SIZE, 3])\n",
    "    pretrained_model.trainable = True\n",
    "\n",
    "    model = tf.keras.Sequential([pretrained_model,\n",
    "                                 tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                                 # tf.keras.layers.Flatten(),\n",
    "                                 \n",
    "                                 # the float32 is needed on\n",
    "                                 # softmax layer when using mixed precision\n",
    "                                 tf.keras.layers.Dense(5, activation='softmax', \n",
    "                                                       dtype=tf.float32)])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XLJNVGwHUDy1",
    "outputId": "24f8c215-db7e-42b4-dc82-f30af367a7d8"
   },
   "outputs": [],
   "source": [
    "with strategy.scope(): \n",
    "    # creating the model in the TPUStrategy scope places the model on the TPU\n",
    "    model = create_model()\n",
    "print(f'{C.Green}')\n",
    "model.summary()\n",
    "model.input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMfenMQcxAAb"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1tLsdxAsEA3b"
   },
   "outputs": [],
   "source": [
    "EPOCHS=12 # 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-ID7vP5mIKs",
    "outputId": "fa90aff0-aa65-40d8-e7a1-6a52cfeeb713"
   },
   "outputs": [],
   "source": [
    "start_time= time.time()\n",
    "with strategy.scope():\n",
    "    model=create_model()\n",
    "    history = model.fit(\n",
    "        training_dataset, validation_data=validation_dataset,\n",
    "        steps_per_epoch=TRAIN_STEPS, epochs=EPOCHS, callbacks=[lr_callback])\n",
    "    final_accuracy = history.history[\"val_accuracy\"][-5:]\n",
    "    print(\"FINAL ACCURACY MEAN-5: \", np.mean(final_accuracy))\n",
    "    print(\"TRAINING TIME: \", time.time() - start_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "VngeUBIdyJ1T",
    "outputId": "011419cc-9fc6-4e0f-b4e1-4d3e42d82245"
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "display_training_curves(history.history['accuracy'][1:], history.history['val_accuracy'][1:], 'accuracy', 211)\n",
    "display_training_curves(history.history['loss'][1:], history.history['val_loss'][1:], 'loss', 212)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKFMWzh0Yxsq"
   },
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZcpoO4jOB-8"
   },
   "outputs": [],
   "source": [
    "# a couple of images to test predictions too\n",
    "some_flowers, some_labels = dataset_to_numpy_util(validation_dataset, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 830
    },
    "id": "2X07EKsqK_RW",
    "outputId": "872990fc-89d0-47e9-a582-76cfa4f0178a"
   },
   "outputs": [],
   "source": [
    "# randomize the input so that you can execute multiple times to change results\n",
    "permutation = np.random.permutation(8*20)\n",
    "some_flowers, some_labels = (some_flowers[permutation], some_labels[permutation])\n",
    "\n",
    "predictions = model.predict(some_flowers, batch_size=16)\n",
    "evaluations = model.evaluate(some_flowers, some_labels, batch_size=16)\n",
    "  \n",
    "print(np.array(CLASSES)[np.argmax(predictions, axis=-1)].tolist())\n",
    "print('[val_loss, val_acc]', evaluations)\n",
    "\n",
    "display_9_images_with_predictions(some_flowers, predictions, some_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ivTV2qPoOB_B"
   },
   "outputs": [],
   "source": [
    "model.save('MobileNet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOVgGwS-OB_K"
   },
   "source": [
    "## Reload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 866
    },
    "id": "j4AAIjcoOB_K",
    "outputId": "e87936dd-e3b6-4814-cb31-25e7b5a45bbe"
   },
   "outputs": [],
   "source": [
    "reload_model = tf.keras.models.load_model('MobileNet_model.h5')\n",
    "\n",
    "predictions = reload_model.predict(some_flowers, batch_size=16)\n",
    "evaluations = reload_model.evaluate(some_flowers, some_labels, batch_size=16)\n",
    "print(np.array(CLASSES)[np.argmax(predictions, axis=-1)].tolist())\n",
    "print('[val_loss, val_acc]', evaluations)\n",
    "print(f'val_loss: {C.IPurple}{evaluations[0]}{C.ColorOff}')\n",
    "print(f'val_acc: {C.IPurple}{evaluations[1]}{C.ColorOff}')\n",
    "display_9_images_with_predictions(some_flowers, predictions, some_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vBqnqlSVsLCW",
    "outputId": "800a3655-9796-43db-f39a-584a3fb6fa21"
   },
   "outputs": [],
   "source": [
    "programEnd = time.time()\n",
    "programElapseTime = (programEnd - programStart) / 60\n",
    "programElapseTime = round(programElapseTime, 2)\n",
    "print(f'completion in {programElapseTime} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "id": "cRfoK_reaOcT",
    "outputId": "fb94ec02-bf1b-48d2-e843-cb635fa0d11d"
   },
   "outputs": [],
   "source": [
    "from os.path import basename\n",
    "sourcePath='/content/GetColabTPU.py'\n",
    "destinationPath=join(\n",
    "    '/content/drive/MyDrive/PythonFiles', basename(sourcePath))\n",
    "print(destinationPath)\n",
    "shutil.copy2(sourcePath, destinationPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "af7ximMlwIBj"
   },
   "outputs": [],
   "source": [
    "\n",
    "https://drive.google.com/file/d/1zapfN9H0eO-8T-XoBbbS3qcOcPVvXejZ/view?usp=drivesdk"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of NewTPU_3.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf22-cpu.2-2.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf22-cpu.2-2:m47"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
